{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_NmzkRaDvQ9",
        "outputId": "b87049b4-82ff-46c8-fb16-7b45ac3d14eb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "FOLDERNAME = 'CS231n/assignments/assignment2/'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
        "!bash get_datasets.sh\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/CS231n/assignments/assignment2/cs231n/datasets\n",
            "/content/drive/My Drive/CS231n/assignments/assignment2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiBkf01nDvRG",
        "outputId": "ec667b49-c302-42f8-a247-40fd1b0a0e89"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "USE_GPU = True\n",
        "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print('using device:', device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcmK3M0eDvRI",
        "outputId": "671d15d8-9ebb-40de-fe81-546feb9e9964"
      },
      "source": [
        "NUM_TRAIN = 49000\n",
        "\n",
        "transform = T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])\n",
        "\n",
        "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
        "                             transform=transform)\n",
        "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
        "                           transform=transform)\n",
        "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
        "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
        "                            transform=transform)\n",
        "loader_test = DataLoader(cifar10_test, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "module_output_shape",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61242ec2-f7f0-4925-c717-c34d7e1fed2f"
      },
      "source": [
        "class ThreeLayerConvNet(nn.Module):\n",
        "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1=nn.Conv2d(in_channel,channel_1,5,stride=1,padding=2)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        self.conv2=nn.Conv2d(channel_1,channel_2,3,stride=1,padding=1)\n",
        "        nn.init.kaiming_normal_(self.conv2.weight)\n",
        "        self.fc=nn.Linear(32*32*channel_2,num_classes)\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "        scores = None\n",
        "        out=self.conv1(x)\n",
        "        out=F.relu(out)\n",
        "        out=self.conv2(out)\n",
        "        out=F.relu(out)\n",
        "        out=flatten(out)\n",
        "        scores=self.fc(out)\n",
        "\n",
        "        return scores\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKtR2O-sDvRR"
      },
      "source": [
        "def check_accuracy_part34(loader, model):\n",
        "    if loader.dataset.train:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  \n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl7tjQfkDvRR"
      },
      "source": [
        "def train_part34(model, optimizer, epochs=1):\n",
        "    model = model.to(device=device)  \n",
        "    for e in range(epochs):\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            model.train()\n",
        "            x = x.to(device=device, dtype=dtype)  \n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "        \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "         \n",
        "            loss.backward()\n",
        "\n",
        "        \n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "                check_accuracy_part34(loader_val, model)\n",
        "                print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "module_accuracy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c851da-1ad8-4488-e526-6574b765136f"
      },
      "source": [
        "learning_rate = 3e-3\n",
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "\n",
        "model = ThreeLayerConvNet(3,channel_1,channel_2,10)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "train_part34(model, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss = 4.7149\n",
            "Checking accuracy on validation set\n",
            "Got 105 / 1000 correct (10.50)\n",
            "\n",
            "Iteration 100, loss = 1.7752\n",
            "Checking accuracy on validation set\n",
            "Got 337 / 1000 correct (33.70)\n",
            "\n",
            "Iteration 200, loss = 1.8295\n",
            "Checking accuracy on validation set\n",
            "Got 394 / 1000 correct (39.40)\n",
            "\n",
            "Iteration 300, loss = 1.6847\n",
            "Checking accuracy on validation set\n",
            "Got 420 / 1000 correct (42.00)\n",
            "\n",
            "Iteration 400, loss = 1.5943\n",
            "Checking accuracy on validation set\n",
            "Got 444 / 1000 correct (44.40)\n",
            "\n",
            "Iteration 500, loss = 1.5398\n",
            "Checking accuracy on validation set\n",
            "Got 460 / 1000 correct (46.00)\n",
            "\n",
            "Iteration 600, loss = 1.4807\n",
            "Checking accuracy on validation set\n",
            "Got 449 / 1000 correct (44.90)\n",
            "\n",
            "Iteration 700, loss = 1.5614\n",
            "Checking accuracy on validation set\n",
            "Got 476 / 1000 correct (47.60)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sequential_accuracy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7918d9ac-27cf-4edb-bb64-cc703ad01e1e"
      },
      "source": [
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "learning_rate = 1e-2\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Conv2d(3,channel_1,5,stride=1,padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channel_1,channel_2,3,stride=1,padding=1),\n",
        "            nn.ReLU(),\n",
        "            Flatten(),\n",
        "            nn.Linear(32*32*channel_2,10),\n",
        "\n",
        ")\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
        "                     momentum=0.9, nesterov=True)\n",
        "\n",
        "train_part34(model, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss = 2.3128\n",
            "Checking accuracy on validation set\n",
            "Got 138 / 1000 correct (13.80)\n",
            "\n",
            "Iteration 100, loss = 1.4471\n",
            "Checking accuracy on validation set\n",
            "Got 433 / 1000 correct (43.30)\n",
            "\n",
            "Iteration 200, loss = 1.4417\n",
            "Checking accuracy on validation set\n",
            "Got 486 / 1000 correct (48.60)\n",
            "\n",
            "Iteration 300, loss = 1.2711\n",
            "Checking accuracy on validation set\n",
            "Got 495 / 1000 correct (49.50)\n",
            "\n",
            "Iteration 400, loss = 1.2399\n",
            "Checking accuracy on validation set\n",
            "Got 545 / 1000 correct (54.50)\n",
            "\n",
            "Iteration 500, loss = 1.1611\n",
            "Checking accuracy on validation set\n",
            "Got 559 / 1000 correct (55.90)\n",
            "\n",
            "Iteration 600, loss = 1.1395\n",
            "Checking accuracy on validation set\n",
            "Got 557 / 1000 correct (55.70)\n",
            "\n",
            "Iteration 700, loss = 0.8636\n",
            "Checking accuracy on validation set\n",
            "Got 575 / 1000 correct (57.50)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}